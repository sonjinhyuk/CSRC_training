{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MalRNN 코드 작성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 필요한 package 설치 확인 및 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 추출된 Stream data 에서의 시퀀스 추출 과정 구축\n",
    "* 추출된 stream data(.csv)에서 필요한 byte stream data 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(data_path, chunk_len, malconv_min_len, len_limit=100000):\n",
    "    \"\"\"\n",
    "    :param str data_path: stream data csv파일의 위치\n",
    "    :param int chunk_len: benign byte stream sampling 길이(정상데이터는 최소 chunk_len 이상이어야 함)\n",
    "    :param int malconv_min_len: malconv 탐지를 위한 최소 길이(악성데이터는 최소 malconv_min_len 이상이어야 함)\n",
    "    :param int len_limit: 시스템 과부하 방지 목적 길이 제한\n",
    "    :return 정상/악성 byte stream data list\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    ### Byte Stream 데이터 추출을 위한 함수 만들기 ###\n",
    "    # data_path에 위치한 파일 열기    \n",
    "    with open(data_path, \"r\", encoding=\"cp949\") as data:\n",
    "        \n",
    "        # 정상/악성 데이터를 저장할 list 생성\n",
    "        benign_data = []\n",
    "        critical_data = []\n",
    "\n",
    "        # 파일 내 Stream data line별로 읽기 \n",
    "        for line in data.readlines():\n",
    "            try:\n",
    "                # len_limit 이내의 데이터에서 추출\n",
    "                if len(line) < len_limit:\n",
    "\n",
    "                    # csv 내의 Stream 이후만 추출하기 위한 \"]\"의 위치 찾은후 이후 데이터만 추출\n",
    "                    look = line.rfind(\"]\")\n",
    "                    line = line[look+2 : ]\n",
    "\n",
    "                    # 추출된 데이터의 개행문자 제거 및 전처리\n",
    "                    line = line.replace(\"\\n\", \"\")\n",
    "                    if line.startswith(\",\"):\n",
    "                        line = line[1:]\n",
    "                    line = line.split(\",\")\n",
    "\n",
    "                    # 전처리된 데이터의 int 변환 및 list 삽입\n",
    "                    line = [int(x,0) for x in line]\n",
    "                    \n",
    "                    # 정상/악성 여부에 따른 최소 길이 확인 및 list 삽입\n",
    "                    if line[1] == 0 and len(line[2:]) > chunk_len:\n",
    "                        ### FILL HERE ###\n",
    "                    elif line[1] == 1 and len(line[2:]) > malconv_min_len:\n",
    "                        ### FILL HERE ###\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    return benign_data, critical_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 생성된 byte stream 악성 여부 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_detection(malconv, gen_bytes):\n",
    "    \"\"\"\n",
    "    :param nn.Module malconv: malconv 모델\n",
    "    :param list gen_bytes: 생성된 byte stream \n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        gen_bytes = torch.from_numpy(np.frombuffer(gen_bytes, dtype=np.uint8)[np.newaxis, :])\n",
    "        malconv_output = F.softmax(malconv(gen_bytes), dim=-1).detach().numpy()[0,1]\n",
    "        return malconv_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 정상 데이터 sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_benign_sample(benign_stream, chunk_len, batch_size, device):\n",
    "    \"\"\"\n",
    "    :param list benign_stream: 정상 byte stream\n",
    "    :param int chunk_len: sampling 길이\n",
    "    :param int batch_size: 한번 학습에 이용할 byte 갯수\n",
    "    :param device: 학습 device(CPU/GPU)에 따른 할당\n",
    "    :return input_stream, target_stream\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    ### 정상 데이터 sampling 만들기 ###\n",
    "    \n",
    "    # input_stream(학습에 사용), target_stream(loss 산정 시 사용) 선언 (batch_size * chunk_len)\n",
    "    input_stream = torch.LongTensor(batch_size, chunk_len)\n",
    "    target_stream = torch.LongTensor(batch_size, chunk_len)\n",
    "    \n",
    "    # batch size 만큼의 for loop 생성\n",
    "    for batch in range(batch_size):\n",
    "\n",
    "        # chunk_len을 고려한 임의의 start index 선정\n",
    "        start_index = ### FILL HERE ###\n",
    "        \n",
    "        # chunk_len을 고려한 end_index 계산\n",
    "        end_index = start_index + chunk_len + 1\n",
    "        \n",
    "        # benign stream data에서 sampling\n",
    "        chunk = ### FILL HERE ###\n",
    "        \n",
    "        # input_stream과 target_stream 저장\n",
    "        input_stream[batch] = torch.as_tensor(chunk[:-1])\n",
    "        target_stream[batch] = torch.as_tensor(chunk[1:])\n",
    "    \n",
    "    # 저장된 input_stream, target_stream device 할당\n",
    "    input_stream = torch.LongTensor(input_stream).to(device)\n",
    "    target_stream = torch.LongTensor(target_stream).to(device)\n",
    "    return input_stream, target_stream   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 학습과정에 필요한 Byte Stream 생성 함수 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_byte(model, base_stream, device, len_to_predict=1000, temperature=0.8):\n",
    "    \"\"\"\n",
    "    :param nn.Module model: Byte Stream 생성할 MalRNN 모델\n",
    "    :param list base_stream: 생성에 이용될 기초 byte stream\n",
    "    :param device: 학습 device(CPU/GPU)에 따른 할당\n",
    "    :param int len_to_predict: 생성할 Byte Stream 갯수\n",
    "    :param float temperature: 분포 smoothing을 위한 지수\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    ### MalRNN을 이용해 byte stream 생성 ###\n",
    "\n",
    "    # 입력된 base stream 적용을 위한 model의 hidden state 초기화\n",
    "    hidden_state = model.init_hidden(1).to(device)\n",
    "\n",
    "    # base stream을 학습에 적합하도록 unsqueeze를 이용한 차원 추가\n",
    "    base_input = torch.LongTensor(base_stream).unsqueeze(0).to(device)\n",
    "    \n",
    "    # 예측 variable 선언 및 base_stream 적용\n",
    "    predict = base_stream\n",
    "\n",
    "    # 마지막 byte stream을 제외한 byte stream model hidden state에 적용\n",
    "    for p in range(len(base_stream) - 1):\n",
    "        _, hidden_state = model(base_input[:, p], hidden_state)\n",
    "\n",
    "    output_result = []\n",
    "    model_input = base_input[:, -1]\n",
    "\n",
    "    # len_to_predict 길이까지 하나씩 byte stream 생성\n",
    "    for p in range(len_to_predict):\n",
    "        output, hidden_state = ### FILL HERE ###\n",
    "        output_result.append(output)\n",
    "\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        predict_stream = torch.multinomial(output_dist, 1)[0]\n",
    "\n",
    "        predict = ### FILL HERE ###\n",
    "        model_input = (\n",
    "            torch.tensor(predict_stream, dtype=torch.long).unsqueeze(0).to(device)\n",
    "        )\n",
    "\n",
    "    return predict.tolist(), output_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. MalRNN 학습과정 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 학습에 필요한 moudle 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rnn_model import CharRNN\n",
    "from MalConv import MalConv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MalRNN에 필요한 파일 경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_data_path = \"../data/3_malrnn_sample.csv\"\n",
    "malconv_weight_path = \"../data/malconv_doc.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_MalRNN():\n",
    "    \n",
    "    ### MalRNN 학습과정 구축 ###\n",
    "\n",
    "    # TODO: 정상/악성 byte stream 호출\n",
    "    benign_data, critical_data = ### FILL HERE ###\n",
    "\n",
    "    # 학습장치(CPU/GPU) 호출\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    print(f\"Current device is {device}\")\n",
    "\n",
    "    # MalConv 로드\n",
    "    malconv = MalConv(channels=256, window_size=512, embd_size=8)\n",
    "    malconv_weight = torch.load(malconv_weight_path, map_location=torch.device('cpu'))\n",
    "    malconv.load_state_dict(malconv_weight)\n",
    "\n",
    "    # TODO: MalRNN 모델 구성하기 (input_size=256, hidden_size=100, output_size=256, model=gru, n_layers=1)\n",
    "    model = ### FILL HERE ###\n",
    "\n",
    "    # MalRNN 모델 학습장치 할당\n",
    "    model.to(device)\n",
    "\n",
    "    # TODO: 학습 loss function 및 optimizer 호출\n",
    "    criterion = ### FILL HERE ###\n",
    "    optimizer = ### FILL HERE ###\n",
    "\n",
    "    # 학습에 필요한 variable 선언\n",
    "    loss_record = []\n",
    "    best_score = -1\n",
    "    best_loss = -1\n",
    "    best_model = None  \n",
    "    \n",
    "    # TODO 매 epoch별 학습 구성\n",
    "    for epoch in range(1, 11):\n",
    "        print(f\"EPOCH {epoch}\")\n",
    "\n",
    "        # 정상 stream data sampling -> input / target benign stream data 수집\n",
    "        input_benign, target_benign = create_benign_sample(\n",
    "            benign_stream=### FILL HERE ###,\n",
    "            chunk_len=200,\n",
    "            batch_size=10,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        # 모델 hidden state 초기화 및 학습장치 할당\n",
    "        hidden_state = model.init_hidden(10)\n",
    "        hidden_state.to(device)\n",
    "\n",
    "        # 모델 parameter 초기화 및 loss variable 선언\n",
    "        model.zero_grad()\n",
    "        loss = 0\n",
    "\n",
    "        # 생성을 위한 임의의 악성 stream data 추출 \n",
    "        base_stream = critical_data[random.randrange(0, len(critical_data))][:1024]\n",
    "        \n",
    "        # 추출한 악성 stream data에 기반한 stream data 생성\n",
    "        predicted, _ = ### FILL HERE ###\n",
    "\n",
    "        # 기반 stream data와 생성된 stream data 결합\n",
    "        candidate = bytearray(base_stream) + bytearray(predicted[0])\n",
    "        \n",
    "        # 결과물에 대한 악성 여부 malconv 확인\n",
    "        malconv_result = ### FILL HERE ###\n",
    "        \n",
    "        # 정상 Stream data를 이용한 MalRNN 생성 학습\n",
    "        for c in range(200):\n",
    "            output, hidden_state = model(input_benign[:, c], hidden_state.to(device))\n",
    "\n",
    "            # 생성한 stream과 실제 stream의 차이(loss) 계산 및 학습 반영\n",
    "            loss += criterion(output.view(10, -1), target_benign[:, c])\n",
    "        \n",
    "        # loss 기록 및 loss를 통한 역전파 계산 및 optimizer step 이동 \n",
    "        loss_record.append(loss)\n",
    "        ### FILL HERE ###\n",
    "        ### FILL HERE ###\n",
    "        print(f\"Epoch {epoch} loss: {loss.data / 200}\")\n",
    "        print(f\"Detection Possibility: {malconv_result : 4f}\")\n",
    "\n",
    "        # loss 및 탐지 확률에 따른 모델 저장\n",
    "        if epoch == 1:\n",
    "            print(\"Saving the first model\")\n",
    "            best_model = model\n",
    "            best_score = malconv_result\n",
    "            best_loss = loss.data / 200\n",
    "        elif best_score > malconv_result:\n",
    "            print(\"Best score updated! Saving...\")\n",
    "            best_model = model\n",
    "            best_score = malconv_result\n",
    "            best_loss = loss.data / 200\n",
    "        elif best_score == malconv_result:\n",
    "            if best_loss > (loss.data / 200):\n",
    "                print(\"Best score updated! Saving...\")\n",
    "                best_model = model\n",
    "                best_score = malconv_result\n",
    "                best_loss = loss.data / 200\n",
    "    \n",
    "    # 학습된 최종 모델 저장\n",
    "    torch.save(best_model, \"./malRNN_doc.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_MalRNN()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
