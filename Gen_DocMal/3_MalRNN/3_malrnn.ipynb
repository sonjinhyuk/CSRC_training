{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MalRNN 코드 작성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 필요한 package 설치 확인 및 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 추출된 Stream data 에서의 시퀀스 추출 과정 구축\n",
    "* 추출된 stream data(.csv)에서 필요한 byte stream data 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(data_path, chunk_len, malconv_min_len, len_limit=100000):\n",
    "    \"\"\"\n",
    "    :param str data_path: stream data csv파일의 위치\n",
    "    :param int chunk_len: benign byte stream sampling 길이(정상데이터는 최소 chunk_len 이상이어야 함)\n",
    "    :param int malconv_min_len: malconv 탐지를 위한 최소 길이(악성데이터는 최소 malconv_min_len 이상이어야 함)\n",
    "    :param int len_limit: 시스템 과부하 방지 목적 길이 제한\n",
    "    :return 정상/악성 byte stream data list\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    ### Byte Stream 데이터 추출을 위한 함수 만들기 ###\n",
    "    # 1. data_path에 위치한 파일 열기\n",
    "    # 2. 정상/악성 데이터를 저장할 list 생성\n",
    "    # 3. len_limit 이내의 데이터에서 추출\n",
    "    # 4. csv 내의 Stream 이후만 추출하기 위한 \"]\"의 위치 찾은후 이후 데이터만 추출\n",
    "    # 5. 추출된 데이터의 개행문자 제거 및 전처리\n",
    "    # 6. 전처리된 데이터의 int 변환 및 list 삽입\n",
    "    # 7. 정상/악성 여부에 따른 최소 길이 확인 및 list 삽입"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 생성된 byte stream 악성 여부 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_detection(malconv, gen_bytes):\n",
    "    \"\"\"\n",
    "    :param nn.Module malconv: malconv 모델\n",
    "    :param list gen_bytes: 생성된 byte stream \n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        gen_bytes = torch.from_numpy(np.frombuffer(gen_bytes, dtype=np.uint8)[np.newaxis, :])\n",
    "        malconv_output = F.softmax(malconv(gen_bytes), dim=-1).detach().numpy()[0,1]\n",
    "        return malconv_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 정상 데이터 sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_benign_sample(benign_stream, chunk_len, batch_size, device):\n",
    "    \"\"\"\n",
    "    :param list benign_stream: 정상 byte stream\n",
    "    :param int chunk_len: sampling 길이\n",
    "    :param int batch_size: 한번 학습에 이용할 byte 갯수\n",
    "    :param device: 학습 device(CPU/GPU)에 따른 할당\n",
    "    :return input_stream, target_stream\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    ### 정상 데이터 sampling 만들기 ###\n",
    "    # 1. input_stream(학습에 사용), target_stream(loss 산정 시 사용) 선언 (batch_size * chunk_len)\n",
    "    # 2. batch size 만큼의 for loop 생성\n",
    "    # 3. chunk_len을 고려한 임의의 start index 선정\n",
    "    # 4. chunk_len을 고려한 end_index 계산\n",
    "    # 5. benign stream data에서 sampling\n",
    "    # 6. input_stream과 target_stream 저장\n",
    "    # 7. 저장된 input_stream, target_stream device 할당 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_benign_sample(benign_stream, chunk_len, batch_size, device):\n",
    "    \"\"\"\n",
    "    :param list benign_stream: 정상 byte stream\n",
    "    :param int chunk_len: sampling 길이\n",
    "    :param int batch_size: 한번 학습에 이용할 byte 갯수\n",
    "    :param device: 학습 device(CPU/GPU)에 따른 할당\n",
    "    :return input_stream, target_stream\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    ### 정상 데이터 sampling 만들기 ###\n",
    "    # 1. input_stream(학습에 사용), target_stream(loss 산정 시 사용) 선언 (batch_size * chunk_len)\n",
    "    # 2. batch size 만큼의 for loop 생성\n",
    "    # 3. chunk_len을 고려한 임의의 start index 선정\n",
    "    # 4. chunk_len을 고려한 end_index 계산\n",
    "    # 5. benign stream data에서 sampling\n",
    "    # 6. input_stream과 target_stream 저장\n",
    "    # 7. 저장된 input_stream, target_stream device 할당 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_benign_sample(benign_stream, chunk_len, batch_size, device):\n",
    "    \"\"\"\n",
    "    :param list benign_stream: 정상 byte stream\n",
    "    :param int chunk_len: sampling 길이\n",
    "    :param int batch_size: 한번 학습에 이용할 byte 갯수\n",
    "    :param device: 학습 device(CPU/GPU)에 따른 할당\n",
    "    :return input_stream, target_stream\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    ### 정상 데이터 sampling 만들기 ###\n",
    "    # 1. input_stream(학습에 사용), target_stream(loss 산정 시 사용) 선언 (batch_size * chunk_len)\n",
    "    # 2. batch size 만큼의 for loop 생성\n",
    "    # 3. chunk_len을 고려한 임의의 start index 선정\n",
    "    # 4. chunk_len을 고려한 end_index 계산\n",
    "    # 5. benign stream data에서 sampling\n",
    "    # 6. input_stream과 target_stream 저장\n",
    "    # 7. 저장된 input_stream, target_stream device 할당  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 학습과정에 필요한 Byte Stream 생성 함수 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_byte(model, base_stream, device, len_to_predict=1000, temperature=0.8):\n",
    "    \"\"\"\n",
    "    :param nn.Module model: Byte Stream 생성할 MalRNN 모델\n",
    "    :param list base_stream: 생성에 이용될 기초 byte stream\n",
    "    :param device: 학습 device(CPU/GPU)에 따른 할당\n",
    "    :param int len_to_predict: 생성할 Byte Stream 갯수\n",
    "    :param float temperature: 분포 smoothing을 위한 지수\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    ### MalRNN을 이용해 byte stream 생성 ###\n",
    "    # 1. 입력된 base stream 적용을 위한 model의 hidden state 초기화\n",
    "    # 2. base stream을 학습에 적합하도록 unsqueeze를 이용한 차원 추가\n",
    "    # 3. 예측 variable 선언 및 base_stream 적용\n",
    "    # 4. 마지막 byte stream을 제외한 byte stream model hidden state에 적용\n",
    "    # 5. len_to_predict 길이까지 하나씩 byte stream 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. MalRNN 학습과정 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 학습에 필요한 moudle 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rnn_model import CharRNN\n",
    "from MalConv import MalConv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MalRNN에 필요한 파일 경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_data_path = \"\"\n",
    "malconv_weight_path = \"../data/malconv_doc.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_MalRNN():\n",
    "    \n",
    "    ### MalRNN 학습과정 구축 ###\n",
    "\n",
    "    # TODO: 정상/악성 byte stream 호출\n",
    "\n",
    "    # 학습장치(CPU/GPU) 호출\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    print(f\"Current device is {device}\")\n",
    "\n",
    "    # MalConv 로드\n",
    "    malconv = MalConv(channels=256, window_size=512, embd_size=8)\n",
    "    malconv_weight = torch.load(malconv_weight_path)\n",
    "    malconv.load_state_dict(malconv_weight)\n",
    "\n",
    "    # TODO: MalRNN 모델 구성하기\n",
    "\n",
    "    # MalRNN 모델 학습장치 할당\n",
    "    model.to(device)\n",
    "\n",
    "    # TODO: 학습 loss function 및 optimizer 호출\n",
    "\n",
    "\n",
    "    # 학습에 필요한 variable 선언\n",
    "    loss_record = []\n",
    "    best_score = -1\n",
    "    best_loss = -1\n",
    "    best_model = None  \n",
    "    \n",
    "    # TODO 매 epoch별 학습 구성\n",
    "    # 1. 정상 stream data sampling -> input / target benign stream data 수집\n",
    "    # 2. 모델 hidden state 초기화 및 학습장치 할당\n",
    "    # 3. 모델 parameter 초기화 및 loss variable 선언\n",
    "    # 4. 악성 stream data 추출 및 생성된 stream으로 악성 회피여부 확인\n",
    "    # 5. 길이만큼 매 byte stream 학습 및 다음 byte stream 생성하여 loss 계산\n",
    "    # 6. loss에 따른 MalRNN model parameter 조정\n",
    "    # 7. loss 및 탐지 확률에 따른 모델 저장\n",
    "    \n",
    "    # 학습된 최종 모델 저장\n",
    "    torch.save(best_model, \"./malRNN_doc.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
