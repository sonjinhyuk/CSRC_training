{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MalRNN 코드 작성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 필요한 package 설치 확인 및 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 추출된 Stream data 에서의 시퀀스 추출 과정 구축\n",
    "* 추출된 stream data(.csv)에서 필요한 byte stream data 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(data_path, chunk_len, malconv_min_len, len_limit=100000):\n",
    "    \"\"\"\n",
    "    :param str data_path: stream data csv파일의 위치\n",
    "    :param int chunk_len: benign byte stream sampling 길이(정상데이터는 최소 chunk_len 이상이어야 함)\n",
    "    :param int malconv_min_len: malconv 탐지를 위한 최소 길이(악성데이터는 최소 malconv_min_len 이상이어야 함)\n",
    "    :param int len_limit: 시스템 과부하 방지 목적 길이 제한\n",
    "    :return 정상/악성 byte stream data list\n",
    "    \"\"\"\n",
    "    \n",
    "    ### Byte Stream 데이터 추출을 위한 함수 만들기 ###\n",
    "    # 1. data_path에 위치한 파일 열기\n",
    "    # 2. 정상/악성 데이터를 저장할 list 생성\n",
    "    # 3. len_limit 이내의 데이터에서 추출\n",
    "    # 4. csv 내의 Stream 이후만 추출하기 위한 \"]\"의 위치 찾은후 이후 데이터만 추출\n",
    "    # 5. 추출된 데이터의 개행문자 제거 및 전처리\n",
    "    # 6. 전처리된 데이터의 int 변환 및 list 삽입\n",
    "    # 7. 정상/악성 여부에 따른 최소 길이 확인 및 list 삽입\n",
    "    \n",
    "    with open(data_path, \"r\", encoding=\"cp949\") as data:\n",
    "        benign_data = []\n",
    "        critical_data = []\n",
    "\n",
    "        for line in data.readlines():\n",
    "            try:\n",
    "                if len(line) < len_limit:\n",
    "                    look = line.rfind(\"]\")\n",
    "                    line = line[look+2 : ]\n",
    "                    line = line.replace(\"\\n\", \"\")\n",
    "                    if line.startswith(\",\"):\n",
    "                        line = line[1:]\n",
    "                    line = line.split(\",\")\n",
    "                    line = [int(x,0) for x in line]\n",
    "\n",
    "                    if line[1] == 0 and len(line[4:]) > chunk_len:\n",
    "                        benign_data.append(line[4:])\n",
    "                    elif line[1] == 1 and len(line[4:]) > malconv_min_len:\n",
    "                        critical_data.append(line[4:])\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    return benign_data, critical_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 생성된 byte stream 악성 여부 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_detection(malconv, gen_bytes):\n",
    "    \"\"\"\n",
    "    :param nn.Module malconv: malconv 모델\n",
    "    :param list gen_bytes: 생성된 byte stream \n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        gen_bytes = torch.from_numpy(np.frombuffer(gen_bytes, dtype=np.uint8)[np.newaxis, :])\n",
    "        malconv_output = F.softmax(malconv(gen_bytes), dim=-1).detach().numpy()[0,1]\n",
    "        return malconv_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 정상 데이터에 대한 sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_benign_sample(benign_stream, chunk_len, batch_size, device):\n",
    "    \"\"\"\n",
    "    :param list benign_stream: 정상 byte stream\n",
    "    :param int chunk_len: sampling 길이\n",
    "    :param int batch_size: 한번 학습에 이용할 byte 갯수\n",
    "    :param device: 학습 device(CPU/GPU)에 따른 할당\n",
    "    :return input_stream, target_stream\n",
    "    \"\"\"\n",
    "    ### 정상 데이터 sampling 만들기 ###\n",
    "    # 1. input_stream(학습에 사용), target_stream(loss 산정 시 사용) 선언 (batch_size * chunk_len)\n",
    "    # 2. batch size 만큼의 for loop 생성\n",
    "    # 3. chunk_len을 고려한 임의의 start index 선정\n",
    "    # 4. chunk_len을 고려한 end_index 계산\n",
    "    # 5. benign stream data에서 sampling\n",
    "    # 6. input_stream과 target_stream 저장\n",
    "    # 7. 저장된 input_stream, target_stream device 할당\n",
    "    \n",
    "    input_stream = torch.LongTensor(batch_size, chunk_len)\n",
    "    target_stream = torch.LongTensor(batch_size, chunk_len)\n",
    "    for batch in range(batch_size):\n",
    "        start_index = random.randrange(0, len(benign_stream) - chunk_len)\n",
    "        end_index = start_index + chunk_len + 1\n",
    "        chunk = benign_stream[start_index : end_index]\n",
    "        input_stream[batch] = torch.as_tensor(chunk[:-1])\n",
    "        target_stream[batch] = torch.as_tensor(chunk[1:])\n",
    "    input_stream = torch.LongTensor(input_stream).to(device)\n",
    "    target_stream = torch.LongTensor(target_stream).to(device)\n",
    "    return input_stream, target_stream   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
